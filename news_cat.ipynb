{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36deb54-fa34-4e09-81d3-0ba7729f1a04",
   "metadata": {},
   "source": [
    "# Определение тематики текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75988930-ef00-4f57-bd2f-cc3da46f7003",
   "metadata": {},
   "source": [
    "<p>В рамках данного проекта решается задача определения тематики текста.</p>\n",
    "<p>Используется предобученная модель BERT.</p>\n",
    "<p>Дообучение модели производится на размеченных текстах, которые представляют собой предложения из новостей различных тематик.</p>\n",
    "<p>Число текстов - 5740, число тем - 14.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6927ad6-c7a5-4db2-8867-50b229ecdbcd",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a316849-a5e0-4190-a360-0b76ba754590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd756005-25f3-40be-87ad-7bcdc27f5d86",
   "metadata": {},
   "source": [
    "### Объявление констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc63f5ef-8908-47ca-9745-c02216023e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начальное значение генератора случайных чисел\n",
    "RANDOM_STATE = 12345\n",
    "\n",
    "# Размер тестовой выборки\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "# Размер валидационной выборки\n",
    "VALIDATION_SIZE = 0.2\n",
    "\n",
    "# Число эпох обучения\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09c056-06f7-4eb3-ab6a-11712db18666",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c50a48d-e506-4453-b4e7-e56d71c7c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файла\n",
    "data = pd.read_csv('news/texts.csv', sep=';')\n",
    "\n",
    "# Удаляем строки с пропусками\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86202857-1931-41bc-b510-a10cd434f23c",
   "metadata": {},
   "source": [
    "### Исследовательский анализ и предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e887f249-9845-41d6-b48c-156b64afb4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5740 entries, 0 to 5742\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   topic   5740 non-null   float64\n",
      " 1   text    5740 non-null   object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 134.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Выведем информацию о датафрейме\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78ab2e-3ad9-4e28-b06f-a49610a4d216",
   "metadata": {},
   "source": [
    "<p>Заменим тип столбца с метками классов на int.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda53e73-53e4-473b-940d-966c5a857eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразовываем таргет в int\n",
    "data['topic'] = data['topic'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e2e25e-0564-4b5c-9084-7bd591e9cc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем число пропусков\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df68fc-23e2-4231-af90-bf9d8201a3d5",
   "metadata": {},
   "source": [
    "<p>Пропусков не обнаружено.</p>\n",
    "<p>Пррверим датафрейм на наличие дубликатов.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5813480-b04d-49e6-8eb8-864ec53822dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем число дубликатов\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4122d9f-3956-41ed-b40d-efad341575a7",
   "metadata": {},
   "source": [
    "<p>Обнаружено 176 дубликатов, произведем их удаление.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ad2bb9-d5cf-42c3-b89c-9977ebb2bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим дубликаты\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334f4fd-3bca-4550-874c-5d0af0b729a2",
   "metadata": {},
   "source": [
    "<p>Выведем список уникальных классов и их число.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b1e29e-287d-46bd-b860-78c38d2c25e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные классы: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 99]\n",
      "Число классов: 14\n"
     ]
    }
   ],
   "source": [
    "# Выведем уникальные классы (темы)\n",
    "print('Уникальные классы:', sorted(data['topic'].unique()))\n",
    "\n",
    "# Выведем число уникальных классов\n",
    "print('Число классов:', len(data['topic'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d754b4-0e23-4498-a434-7d56a082d036",
   "metadata": {},
   "source": [
    "<p>Создадим словарь с текстовыми метками классов.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7a9d3a-f367-4302-94c1-060c6aeba41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь с темами\n",
    "themes = {\n",
    "    0: 'Экономика',\n",
    "    1: 'Финансы',\n",
    "    2: 'Акции',\n",
    "    3: 'Компании',\n",
    "    4: 'Технологии',\n",
    "    5: 'Политика',\n",
    "    6: 'Наука',\n",
    "    7: 'Здоровье',\n",
    "    8: 'Энергетика',\n",
    "    9: 'Происшествия',\n",
    "    10: 'Спорт',\n",
    "    15: 'Общество',\n",
    "    20: 'Климат',\n",
    "    99: 'Прочее'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0674b862-3b8b-49d1-a132-8ba16107600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_text\n",
       "Политика        3402\n",
       "Компании         666\n",
       "Экономика        404\n",
       "Энергетика       396\n",
       "Происшествия     216\n",
       "Акции            152\n",
       "Финансы          143\n",
       "Технологии        73\n",
       "Прочее            44\n",
       "Наука             31\n",
       "Спорт             26\n",
       "Общество           8\n",
       "Здоровье           2\n",
       "Климат             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим столбец с текстовым описанием классов\n",
    "data['topic_text'] = data['topic'].apply(lambda x: themes[x])\n",
    "\n",
    "# Вычислим число текстов в каждой категории\n",
    "data['topic_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b0c7d-acf2-4cbe-a972-f4e69c0c8fc4",
   "metadata": {},
   "source": [
    "<p>В наибольшей степени представлены новости из категорий 'Политика', 'Компании', 'Экономика', 'Энергетика'.</p>\n",
    "<p>В остальных категориях число примеров гораздо меньше, что может отрицательно повлиять на обучение и качество предсказания данных категорий.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815a37f6-3445-4742-8594-83bd81ec41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Применим кодирование\n",
    "data['encoded_topic'] = encoder.fit_transform(data['topic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cdf88-0a9c-4726-b80e-932e6decd6f7",
   "metadata": {},
   "source": [
    "### Создание выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77773c48-9a52-400a-80ee-e81c53bdfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список с текстами\n",
    "texts = list(data['text'])\n",
    "\n",
    "# Список с категориями\n",
    "labels = list(data['encoded_topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d86d0c3e-ee57-4a4a-a9c8-526f66611742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучающая и тестовая выбоки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE)\n",
    "\n",
    "# Дополнительное разделение обучающей выборки на обучающую и валидационную\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=VALIDATION_SIZE,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352015d-d5ee-419c-8709-bbb1a3314131",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a358acdf-61bd-4c78-8ea6-54152e3fbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число классов\n",
    "num_labels = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e807db-0216-4e8c-a8b4-95d0e6267760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предварительно обученной модели DistilBERT\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a5c37-4d13-4b63-81c4-605c02986253",
   "metadata": {},
   "source": [
    "### Создание датасетов и загрузчиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f48e9420-a1ce-4a6b-8463-b7dbbfc88d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69d690d7-6eba-425f-bfcc-800fcb2372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "max_length = 128\n",
    "\n",
    "# Обучающий датасет и загрузчик\n",
    "dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Валидационный датасет и загрузчик\n",
    "dataset = TextDataset(X_val, y_val, tokenizer, max_length)\n",
    "val_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Тестовый датасет и загрузчик\n",
    "dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9d72f-8f3e-4282-a7a3-e53c1745851d",
   "metadata": {},
   "source": [
    "### Fine-tuning модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a860ef-a05d-4d0d-a5b2-314a051c7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Начальное значение потерь\n",
    "avg_train_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dffc0ec-057b-4582-b54c-00f274c3d149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3565, Val Loss: 0.9545, Accuracy: 0.7329, t=5.93\n",
      "Epoch 2, Train Loss: 0.7585, Val Loss: 0.7264, Accuracy: 0.794, t=5.25\n",
      "Epoch 3, Train Loss: 0.5018, Val Loss: 0.636, Accuracy: 0.8168, t=5.26\n",
      "Epoch 4, Train Loss: 0.3531, Val Loss: 0.5737, Accuracy: 0.8251, t=5.25\n",
      "Epoch 5, Train Loss: 0.2513, Val Loss: 0.5949, Accuracy: 0.8431, t=5.19\n",
      "Epoch 6, Train Loss: 0.191, Val Loss: 0.6041, Accuracy: 0.8395, t=5.14\n",
      "Epoch 7, Train Loss: 0.1451, Val Loss: 0.65, Accuracy: 0.8311, t=5.22\n",
      "Epoch 8, Train Loss: 0.1241, Val Loss: 0.5235, Accuracy: 0.8611, t=5.28\n",
      "Epoch 9, Train Loss: 0.0854, Val Loss: 0.576, Accuracy: 0.8503, t=5.28\n",
      "Epoch 10, Train Loss: 0.0603, Val Loss: 0.5783, Accuracy: 0.8623, t=5.28\n",
      "CPU times: user 59min 10s, sys: 33min 42s, total: 1h 32min 52s\n",
      "Wall time: 53min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Обучение модели\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):  # Количество эпох обучения\n",
    "    # Старт таймера\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_losses = []\n",
    "    len_batch = len(dataloader)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        train_losses.append(loss.item())\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Валидация\n",
    "    val_losses = []\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            val_targets = batch[\"labels\"]\n",
    "            batch = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
    "            }\n",
    "            val_outputs = model(**batch)\n",
    "            val_loss = criterion(val_outputs.logits, val_targets)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            # Получение предсказанных меток\n",
    "            _, preds = torch.max(val_outputs.logits, dim=1)\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    t = round((time.time() - start_time)/60, 2)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {round(avg_train_loss.item(),4)}, Val Loss: {round(avg_val_loss, 4)}, Accuracy: {round(accuracy, 4)}, t={t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d191aaf-ec24-49dd-b3ec-949c14ae0f59",
   "metadata": {},
   "source": [
    "### Проверка на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7e66137-8c93-4625-84e0-c5b9683cddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5174, Accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "# Тестирование модели\n",
    "model.eval()\n",
    "test_losses = []\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        test_targets = batch[\"labels\"]\n",
    "        batch = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
    "        }\n",
    "        test_outputs = model(**batch)\n",
    "        test_loss = criterion(test_outputs.logits, test_targets)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        # Получение предсказанных меток\n",
    "        _, preds = torch.max(test_outputs.logits, dim=1)\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(test_targets.cpu().numpy())\n",
    "\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Loss: {round(avg_test_loss, 4)}, Accuracy: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c38627-a685-44fc-afc8-6bd659ac4aa6",
   "metadata": {},
   "source": [
    "### Инференс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48da893-0af7-4803-9b58-fd216da039ed",
   "metadata": {},
   "source": [
    "<p>Подготовим функцию для предсказания темы текста при помощи обученной модели.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d62832-ac5e-4f99-9ddd-081457bd3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция предсказывает тематику текста\n",
    "def predict_class(text):\n",
    "    \n",
    "    # Токенизация и преобразование текста в тензор\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Получение предсказания\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Преобразование логитов в вероятности\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "    # Определение класса с наибольшей вероятностью\n",
    "    _, predicted_class = torch.max(probs, dim=1)\n",
    "\n",
    "    return predicted_class.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108079d-3ac2-4d46-a752-f60000d94a01",
   "metadata": {},
   "source": [
    "<p>Создадим новые предложения различных тематик для проверки работы модели.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "403688df-ca53-4129-8e16-1335d7bb2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример текста для классификации\n",
    "texts = []\n",
    "texts.append('Президент Бразилии рассчитывает на урегулирование через переговоры.')\n",
    "texts.append('Илон Маск купил сервис микроблогов в прошлом году. Сумма сделки составила $44 млрд. Сделка была объявлена в апреле, однако закрыта была в конце октября после длительных переговором между сторонами.')\n",
    "texts.append('Промышленный индекс ISM в США в июне неожиданно опустился ниже 50 пунктов.')\n",
    "texts.append('В середине торгов цена Brent перешла к росту, подорожав до 80 долл. за баррель.')\n",
    "texts.append('Рост ВВП Франции в 2025 г. составил 1,6%.')\n",
    "texts.append('Объем денежных перевод из-за рубежа в Грузию в 2023 г. составил 4,1 млрд долл. (-6,8% к предыдущему году). Поступления из РФ упали на 27,5% (1,5 млрд долл.).')\n",
    "texts.append('Nasdaq уведомила Qiwi plc о делистинге ее американских депозитарных акций. Qiwi намерена обжаловать это решение.')\n",
    "texts.append('Футболисты сборной Англии победили Словакию со счетом 4:2 в матче чемпионата Европы, а Испания обыграла Грузию (2:0).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db7393-ba70-48af-ae43-dd76a7b725cc",
   "metadata": {},
   "source": [
    "<p>Выведем предсказанные тематики текстов и сами тексты.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad02bddd-cc36-406f-94c8-99100043254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 7.15 µs\n",
      "Политика - Президент Бразилии рассчитывает на урегулирование через переговоры.\n",
      "Компании - Илон Маск купил сервис микроблогов в прошлом году. Сумма сделки составила $44 млрд. Сделка была объявлена в апреле, однако закрыта была в конце октября после длительных переговором между сторонами.\n",
      "Экономика - Промышленный индекс ISM в США в июне неожиданно опустился ниже 50 пунктов.\n",
      "Энергетика - В середине торгов цена Brent перешла к росту, подорожав до 80 долл. за баррель.\n",
      "Экономика - Рост ВВП Франции в 2025 г. составил 1,6%.\n",
      "Финансы - Объем денежных перевод из-за рубежа в Грузию в 2023 г. составил 4,1 млрд долл. (-6,8% к предыдущему году). Поступления из РФ упали на 27,5% (1,5 млрд долл.).\n",
      "Акции - Nasdaq уведомила Qiwi plc о делистинге ее американских депозитарных акций. Qiwi намерена обжаловать это решение.\n",
      "Спорт - Футболисты сборной Англии победили Словакию со счетом 4:2 в матче чемпионата Европы, а Испания обыграла Грузию (2:0).\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Выполним предсказание на новых примерах\n",
    "for text in texts:\n",
    "    print(themes[predict_class(text)], '-', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d324e0-724c-4956-aff3-9fffdf9ed937",
   "metadata": {},
   "source": [
    "<p>Модель верно определила тематики текстов, включая минорные классы (например, спорт).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69931d-351c-4c78-8692-ae7732881edc",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1daf4b-c2a5-44a6-a596-040882625f6c",
   "metadata": {},
   "source": [
    "<p>В ходе работы над проектом было сделано:</p>\n",
    "<ul>\n",
    "    <li>Загружены необходимые библиотеки.</li>\n",
    "    <li>Объявлены константы.</li>\n",
    "    <li>Загружены данные.</li>\n",
    "    <li>Проведены предобработка и исследовательский анализ данных:<br>\n",
    "        - тип данных в столбце topic изменен на int;<br>\n",
    "        - проведена проверка на пропуски (пропуски не обнаружены);<br>\n",
    "        - обнаружены и удалены дубликаты;<br>\n",
    "        - подготовлен словарь с текстовыми обозначениями классов;<br>\n",
    "        - проанализирована частотность классов в датафрейме (наиболее часто встречаются 'Политика', 'Компании', 'Экономика', 'Энергетика');<br>\n",
    "        - закодирован таргет.</li>\n",
    "    <li>Данные разделены на выборки: обучающую, валидационную и тестовую.</li>\n",
    "    <li>Загружена модель BERT и токенизатор.</li>\n",
    "    <li>Созданы датасеты и загрузчики.</li>\n",
    "    <li>Произведено дообучение нейросети (модели BERT). Значение метрики Accuracy на валидации составило 0,8623.</li>\n",
    "    <li>Произведена проверка модели на тестовых данных. Значение Accuracy на тесте равно 0,8728.</li>\n",
    "    <li>Проведена проверка модели на новых текстах. Для 8 текстов разных тематик предсказания классов выполнены верно.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406454e-3adc-4582-8290-4c078539487b",
   "metadata": {},
   "source": [
    "<p>Возможные доработки модели:</p>\n",
    "<ul>\n",
    "    <li>Увеличение объема обучающих данных. Для этого потребуется разметка новых текстов.</li>\n",
    "    <li>Применение коэффициента l2_lambda для предотвращения переобучения модели.</li>\n",
    "    <li>Подбор гиперпараметров при помощи Optuna: шага обучения и коэффициента l2_lambda.</li>\n",
    "    <li>Объединение низкочастотных тематик, близких по содержанию (наука, технологии).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea7bf4-7c35-4d94-bc81-2cab3d5bec36",
   "metadata": {},
   "source": [
    "<p>Практическая применимость модели:</p>\n",
    "<ul>\n",
    "    <li>После проведения доработок модель может быть использована для определения тематик новостей.</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db3b2a-0acf-44a7-83da-2a07b1c2fc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
